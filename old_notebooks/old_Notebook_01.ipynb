{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table-of-content  \n",
    "\n",
    "[Packages](#Import-Packages)  \n",
    "[AOI](#AOI)  \n",
    "[Bare Soil](#Bare-Soil)  \n",
    "[Corine Land Cover](#Corine-Land-Cover-(CLC))  \n",
    "[Precipitaion Data](#Precipitaion-Data)  \n",
    "[Soil Moisture](#Soil-Moisture)  \n",
    "[Sentinel1 derives soil-moisture](#Sentinel1-derives-soil-moisture)    \n",
    "[Get CSV for Datasets](#Get-CSV-for-Datasets)  \n",
    "[Data Visualisation](#Data-Visualisation)  \n",
    "[Collection of commands](#Collection-of-commands)  \n",
    "[Collection of Notebook snippets](#Collection-of-Notebook-snippets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earth Engine Communicator \n",
    "from-gee-to-numpy-to-geotiff https://mygeoblog.com/2017/10/06/from-gee-to-numpy-to-geotiff/  \n",
    "API DOC: https://developers.google.com/earth-engine/api_docs#eefeatureget  \n",
    "ReduceRegion https://developers.google.com/earth-engine/reducers_reduce_region  \n",
    "Scale https://developers.google.com/earth-engine/scale  \n",
    "Histogram Matching https://gis.stackexchange.com/questions/332121/histogram-matching-in-google-earth-engine    \n",
    "Determining the sentinel 1 tracks https://gis.stackexchange.com/questions/286922/determining-if-sentinel-1-orbit-is-ascending-or-descending-from-absolute-orbit-n    \n",
    "create sample from feature collection https://mygeoblog.com/2019/04/03/create-sample-from-feature-collection/    \n",
    "Jupter EE map https://github.com/spadarian/jupyter_ee_map    \n",
    "Tutorials https://github.com/csaybar/EEwPython\n",
    "TimeSeries and other nice Stuff https://github.com/tylere/PyDataNYC2017/blob/master/ipynb/satellite_analysis.ipynb\n",
    "https://eeconvert.readthedocs.io/en/latest/eeconvert.html  \n",
    "https://mygeoblog.com/2019/08/21/google-earth-engine-to-numpy/  \n",
    "\n",
    "TO-DO: change ReduceRegion function by adding crs and scale, to get   \n",
    "        projection = im.projection().getInfo()['crs']**im.projection().getInfo()['crs']  \n",
    "        im_reduce = im.reduceRegion(reducer = ee.Reducer.mean(),geometry = ried_225_222,crs=projection,scale = 100, maxPixels= 1e9)    \n",
    "        Tide up import PAckages   \n",
    "        Function Section?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages\n",
    "pip install earthengine-python-api??\n",
    "conda install ipykernel\n",
    "python -m ipykernel install --user\n",
    "conda install -c conda-forge geopandas\n",
    "conda install -c conda-forge ipyleaflet \n",
    "conda install -c conda-forge shapely \n",
    "conda install -c conda-forge scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import ee.mapclient\n",
    "import datetime\n",
    "import IPython.display\n",
    "from IPython.display import Image\n",
    "import bqplot\n",
    "import ipywidgets\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2) # for printing pretty idk what it is... print with pp.pprint(print stuff)\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import dates\n",
    "%matplotlib inline\n",
    "from shapely.geometry import shape\n",
    "import skimage\n",
    "import traitlets\n",
    "import dateutil.parser\n",
    "import numpy as np\n",
    "import ipyleaflet\n",
    "from ipyleaflet import (LayersControl, basemaps, basemap_to_tiles, LayerGroup, Map, Polygon, GeoJSON)\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "# Connect to Earth Engine API\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AOI\n",
    "[Table of content](#Table-of-content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AOI\n",
    "ried = ee.FeatureCollection('users/tillmueller1990/ried_roi') #Depricated not really Hessisches Ried\n",
    "ried_225_222 = ee.FeatureCollection('users/tillmueller1990/ried_225_222') # Use this but the boundary isn't that precise at borders, got it from wms layer \n",
    "germany = ee.FeatureCollection('USDOS/LSIB_SIMPLE/2017').filter(ee.Filter.eq('country_na','Germany'))\n",
    "\n",
    "# Create an empty image into which to paint the features, cast to byte.\n",
    "empty = ee.Image().byte();\n",
    "# Paint all the polygon edges with the same number and width, display.\n",
    "germany_outline = empty.paint(germany, 1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets \n",
    "[Table of content](#Table-of-content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precipitation\n",
    "[Table of content](#Table-of-content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation_gernsheim = ee.FeatureCollection([\n",
    "            ee.Feature(ee.Geometry.Point(8.489,49.762))\n",
    "            ])\n",
    "\n",
    "Map.addLayer(precipitation_gernsheim.draw())\n",
    "Map.centerObject(precipitation_gernsheim, zoom=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bare Soil\n",
    "[Table of content](#Table-of-content)  \n",
    "https://github.com/brmagnuson/LandFallowingInEarthEngine   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://github.com/gee-community/gee_tools/blob/master/notebooks/cloud_mask/cloud_masking.ipynb  \n",
    "https://mygeoblog.com/2019/01/04/harmonizing-sentinel-2-and-landsat-8/   Mergin s2 und landsat\n",
    "\n",
    "To-Do: Sentinel 2 Cloud mask  \n",
    "maybe merge all together?  \n",
    "Make indize bands  \n",
    "export IC with indize bands as pandas dataframe\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geetools import ui, cloud_mask\n",
    "from ipygee import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_geometry(ImageCollection):\n",
    "    geometry = ImageCollection.geometry().getInfo()\n",
    "    #geometry = [x for x in geometry['coordinates']]\n",
    "    return geometry\n",
    "\n",
    "def clip_aoi(ImageCollection):\n",
    "    im = ImageCollection.clip(ried_225_222)\n",
    "    return im\n",
    "\n",
    "def show_tiles(ImageCollection):\n",
    "    geometry = get_geometry(ImageCollection)\n",
    "    geometry_list = list(geometry['coordinates'])\n",
    "    flattened_list = [y for x in geometry_list for y in x] #De flatter list \n",
    "    unique_list = []\n",
    "    unique_list = [x for x in flattened_list if x not in unique_list]\n",
    "    print(\"different tiles: \",len(unique_list))\n",
    "    m = Map(center=(49.6252978589571, 8.34580993652344), zoom=7)\n",
    "    geo_json = GeoJSON(data=geometry, style = {'color': 'green', 'opacity':1, 'weight':1.9, 'dashArray':'9', 'fillOpacity':0.1})\n",
    "    m.add_layer(geo_json)\n",
    "    dc = ipyleaflet.DrawControl()\n",
    "    m.add_control(dc)\n",
    "    m.add_control(LayersControl())\n",
    "    return m\n",
    "    \n",
    "def get_properties_l(ImageCollection):\n",
    "    features = ImageCollection.getInfo()['features']\n",
    "    dict_list = []\n",
    "    for f in features:\n",
    "        prop = f['properties']\n",
    "        dict_list.append(prop)\n",
    "    df = pd.DataFrame.from_records(dict_list).drop(['system:footprint'],axis=1)\n",
    "    #Pandas Series of unique distinc values in df\n",
    "    unique = df.nunique()\n",
    "    im_id_list = [item.get('id') for item in ImageCollection.getInfo().get('features')]\n",
    "    date_list = [datetime.datetime.strptime(x[36:44],'%Y%m%d') for x in im_id_list]\n",
    "    #property_names = list(df.columns.values) \n",
    "    return unique, im_id_list, date_list\n",
    "\n",
    "def getQABits(image, start, end, mascara):\n",
    "    # Compute the bits we need to extract.\n",
    "    pattern = 0\n",
    "    for i in range(start,end+1):\n",
    "        pattern += 2**i\n",
    "    # Return a single band image of the extracted QA bits, giving the     band a new name.\n",
    "    return image.select([0], [mascara]).bitwiseAnd(pattern).rightShift(start)\n",
    "#A function to mask out cloudy pixels.\n",
    "\n",
    "def cloudMaskL457(image):\n",
    "    qa = image.select('pixel_qa');\n",
    "    #If the cloud bit (5) is set and the cloud confidence (7) is high\n",
    "    #or the cloud shadow bit is set (3), then it's a bad pixel.\n",
    "    cloud = qa.bitwiseAnd(1 << 5).And(qa.bitwiseAnd(1 << 7)).Or(qa.bitwiseAnd(1 << 3))\n",
    "    #Remove edge pixels that don't occur in all bands\n",
    "    mask2 = image.mask().reduce(ee.Reducer.min());\n",
    "    return image.updateMask(cloud.Not()).updateMask(mask2)\n",
    "\n",
    "def maskL8sr(image):\n",
    "    #Bits 3 and 5 are cloud shadow and cloud, respectively.\n",
    "    cloudShadowBitMask = (1 << 3)\n",
    "    cloudsBitMask = (1 << 5);\n",
    "    #Get the pixel QA band.\n",
    "    qa = image.select('pixel_qa')\n",
    "    #Both flags should be set to zero, indicating clear conditions.\n",
    "    mask = qa.bitwiseAnd(cloudShadowBitMask).eq(0).And(qa.bitwiseAnd(cloudsBitMask).eq(0))\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "def maskQuality(image):\n",
    "    # Select the QA band.\n",
    "    QA = image.select('pixel_qa')\n",
    "    # Get the internal_cloud_algorithm_flag bit.\n",
    "    sombra = getQABits(QA,3,3,'cloud_shadow')\n",
    "    nubes = getQABits(QA,5,5,'cloud')\n",
    "    #  var cloud_confidence = getQABits(QA,6,7,  'cloud_confidence')\n",
    "    cirrus_detected = getQABits(QA,9,9,'cirrus_detected')\n",
    "    #var cirrus_detected2 = getQABits(QA,8,8,  'cirrus_detected2')\n",
    "    #Return an image masking out cloudy areas.\n",
    "    return image.updateMask(sombra.eq(0)).updateMask(nubes.eq(0).updateMask(cirrus_detected.eq(0)))\n",
    "\n",
    "def maskS2clouds(image):\n",
    "    qa = image.select('QA60')\n",
    "    #Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "    cloudBitMask = 1 << 10\n",
    "    cirrusBitMask = 1 << 11\n",
    "    #Both flags should be set to zero, indicating clear conditions.\n",
    "    mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "    return image.updateMask(mask).divide(10000)\n",
    "\n",
    "#Function to mask out every NDVi <0.1 (Water) \n",
    "def maskNDVI(image):                   \n",
    "    ndvi = image.select('NDVI')\n",
    "    ndvi_mask = ndvi.gte(0.8).And(ndvi.lte(0.1)) \n",
    "    return image.updateMask(ndvi_mask)\n",
    "\n",
    "\n",
    "#https://de.wikipedia.org/wiki/Normalized_Difference_Vegetation_Index\n",
    "#https://www.linkedin.com/pulse/ndvi-ndbi-ndwi-calculation-using-landsat-7-8-tek-bahadur-kshetri\n",
    "\n",
    "\n",
    "def NDVI(image):\n",
    "    ndvi = image.normalizedDifference(['nir','red']) #(first − second) / (first + second)\n",
    "    return image.addBands(ndvi).rename(image.bandNames().add('NDVI'))\n",
    "\n",
    "def SAVI(image): #https://de.wikipedia.org/wiki/Soil-Adjusted_Vegetation_Index bodenbereinigter Vegetationsindex (BBVI) \n",
    "    #A function to compute Soil Adjusted Vegetation Index.\"\"\"\n",
    "    L = 0.5\n",
    "    savi = ee.Image(0).expression('(1 + L) * float(nir - red)/ (nir + red + L)', {'nir': image.select('nir'), 'red': image.select('red'), 'L': 0.5})\n",
    "    return image.addBands(savi).rename(image.bandNames().add('SAVI'))\n",
    "\n",
    "#the normalized difference bare index\n",
    "def NDBI_swir1(image):\n",
    "    ndbi = image.normalizedDifference(['swir1', 'nir'])\n",
    "    return image.addBands(ndbi).rename(image.bandNames().add('NDBI_swir1'))\n",
    "\n",
    "def NDBI_swir2(image):\n",
    "    ndbi = image.normalizedDifference(['swir2', 'nir'])\n",
    "    return image.addBands(ndbi).rename(image.bandNames().add('NDBI_swir2'))\n",
    "\n",
    "#Built Up Index\n",
    "def build_up_index(image):\n",
    "    bu = image.select('NDBI_swir1').subtract(image.select('NDVI'))\n",
    "    return image.addBands(bu).rename(image.bandNames().add('built_up_index_swir1'))\n",
    "                                       \n",
    "                                       \n",
    "#the normalize difference water index\n",
    "def ndwi(image):\n",
    "    return image.normalizedDifference(['B3', 'B8'])\n",
    "\n",
    "\n",
    "#define thresholds\n",
    "bareThreshold = -0.32\n",
    "vegetationThreshold = 0.65\n",
    "waterThreshold = 0.2\n",
    "\n",
    "\"\"\"\n",
    "NDVI = -1 to 0 represent Water bodies\n",
    "NDVI = -0.1 to 0.1 represent Barren rocks, sand, or snow\n",
    "NDVI = 0.2 to 0.5 represent Shrubs and grasslands or senescing crops\n",
    "NDVI = 0.6 to 1.0 represent Dense vegetation or tropical rainforest\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "bandNamesOut_l7 = ['blue','green','red','nir','swir1','temp1','swir2','pixel_qa']\n",
    "bandNamesOut_l8 = ['ultra blue','blue','green','red','nir','swir1','swir2','temp1','temp2','pixel_qa']\n",
    "bandNamesOut_s2 = ['Aerosols','blue','green','red','red edge 1','red edge 2','red edge 3','nir','red edge 4','water vapor','cirrus','swir1','swir2','QA60']\n",
    "bandNamesOut_s2_sr = ['Aerosols','blue','green','red','red edge 1','red edge 2','red edge 3','nir','red edge 4','vater vapor','swir1','swir2','QA60']\n",
    "\n",
    "bandNamesl7 = ['B1','B2','B3','B4','B5','B6','B7','pixel_qa']\n",
    "bandNamesl8 = ['B1','B2','B3','B4','B5','B6','B7','B10','B11','pixel_qa']\n",
    "bandNamesS2 = ['B1','B2','B3','B4','B5','B6','B7','B8','B8A','B9','B10','B11','B12','QA60']\n",
    "bandNamesS2_SR  = ['B1','B2','B3','B4','B5','B6','B7','B8','B8A','B9','B11','B12','QA60']\n",
    "\n",
    "# Filter the L7 collection to a single month.\n",
    "l7_sr = ee.ImageCollection('LANDSAT/LE07/C01/T1_SR').select(bandNamesl7,bandNamesOut_l7).filterDate(datetime.datetime(2009, 1, 1), datetime.datetime(2019, 6, 1)).filterBounds(ried_225_222).map(clip_aoi).map(cloudMaskL457).map(NDVI).map(SAVI).map(NDBI_swir1).map(NDBI_swir2).map(build_up_index) #https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LE07_C01_T1_SR\n",
    "l8_sr = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR').select(bandNamesl8,bandNamesOut_l8).filterDate(datetime.datetime(2009, 1, 1), datetime.datetime(2019, 6, 1)).filterBounds(ried_225_222).map(clip_aoi).map(maskL8sr).map(NDVI).map(SAVI).map(NDBI_swir1).map(NDBI_swir2).map(build_up_index) #https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LC08_C01_T1_SR\n",
    "s2_1c = ee.ImageCollection('COPERNICUS/S2').select(bandNamesS2,bandNamesOut_s2).filterDate(datetime.datetime(2015, 6, 22), datetime.datetime(2017, 3, 27)).filterBounds(ried_225_222).map(clip_aoi).map(maskS2clouds).map(NDVI).map(SAVI).map(NDBI_swir1).map(NDBI_swir2).map(build_up_index) #https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2\n",
    "s2_sr = ee.ImageCollection('COPERNICUS/S2_SR').select(bandNamesS2_SR,bandNamesOut_s2_sr).filterDate(datetime.datetime(2017, 3, 27), datetime.datetime(2019, 6, 1)).filterBounds(ried_225_222).map(clip_aoi).map(maskS2clouds).map(NDVI).map(SAVI).map(NDBI_swir1).map(NDBI_swir2).map(build_up_index) #https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR\n",
    "\n",
    "pp.pprint(l7_sr.first().date().getInfo())\n",
    "pp.pprint(l8_sr.first().bandNames().getInfo())\n",
    "pp.pprint(s2_1c.first().bandNames().getInfo())\n",
    "pp.pprint(s2_sr.first().bandNames().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visL8 = {'bands':['B5','B6','B4'],'min':0, 'max':5000}\n",
    "    \n",
    "visNDVI = {'min': 0, 'max': 1, 'palette': [\n",
    "        'FFFFFF', 'CE7E45', 'DF923D', 'F1B555', 'FCD163',\n",
    "        '99B718', '74A901', '66A000', '529400', '3E8601',\n",
    "        '207401', '056201', '004C00', '023B01', '012E01',\n",
    "        '011D01', '011301' ]}\n",
    "\n",
    "visCLC = {'min': 0, 'max': 8, 'palette': [\n",
    "        'FFFFFF', 'CE7E45', 'DF923D', 'F1B555', 'FCD163',\n",
    "        '99B718', '74A901', '66A000']}\n",
    "\n",
    "visS2 = {'min': 0.0, 'max': 0.3, 'bands': ['B4', 'B3', 'B2']}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corine Land Cover (CLC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load last corine land cover image \n",
    "clc = ee.Image.load('COPERNICUS/CORINE/V18_5_1/100m/2012', -1)\n",
    "\n",
    "# Mask areas where soil moisture measurements valid (farmland cat.:11-16)\n",
    "clc_mask = clc.gte(11).And(clc.lte(16)) #binary map for updateMask\n",
    "clc = clc.updateMask(clc_mask) #set mask for not Farmland\n",
    "\n",
    "# Clip to extend of germany\n",
    "clc = clc.clip(ried_225_222) #image\n",
    "\n",
    "# Feature Collection of clc farmland cat.: 11-16 with 350m resolution\n",
    "clc_vector = clc.reduceToVectors(geometry=ried_225_222, crs=clc.projection(), scale=100, geometryType='polygon', eightConnected = True) #FeatureCollection\n",
    "\n",
    "#im_reduce = im.reduceRegion(reducer = ee.Reducer.mean(),geometry = ried_225_222,crs=projection,scale = 100, maxPixels= 1e9)    \n",
    "#Limit to first 5000 Features \n",
    "#clc_vector = clc_vector.limit(5000)\n",
    "\n",
    "#Sample Points Germany 500\n",
    "random_points = ee.FeatureCollection.randomPoints(clc.geometry(), 5000)\n",
    "\n",
    "\"\"\"\n",
    "def get_area_from_coordinates(element):\n",
    "    from shapely.geometry import Polygon\n",
    "    coords = element\n",
    "    polygon = Polygon(coords)\n",
    "    polygon.area\n",
    "    return \n",
    "def get_greatest_feature(FeatureCollection):\n",
    "    union = FeatureCollection.dissolve()\n",
    "    geometries = union.geometries()\n",
    "    for element in geometries:\n",
    "        print(element)\n",
    "        \n",
    "    #geometry = ImageCollection.geometry().getInfo()\n",
    "    #geometry = [x for x in geometry['coordinates']]\n",
    "    return geometry\n",
    "\n",
    "# geometries() --> Returns the list of geometries in a GeometryCollection, or a singleton list of the geometry for single geometries. für ReduceRegions später wichtig\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geetools import ui, cloud_mask\n",
    "from ipygee import *\n",
    "Map = Map()\n",
    "Map.show()\n",
    "\n",
    "Map.addLayer(clc_geometry.draw('red'),'clc')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precipitaion Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Radolan from Assest \n",
    "radolan = ee.ImageCollection('users/tillmueller1990/radolan/radolan_dwd_germany')\n",
    "\n",
    "#Load GSMAP Hourly Precipitation\n",
    "gsmap = ee.ImageCollection('JAXA/GPM_L3/GSMaP/v6/operational')\n",
    "\n",
    "#CHIRPS 5km daily precipitation \n",
    "chirps  = ee.ImageCollection('UCSB-CHG/CHIRPS/DAILY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soil Moisture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Products provided by NASA, ESA, GEE ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NASA-USDA Global Soil Moisture Data / 3 days / 2010- 2019 / 0.25 arc degrees / SMOS lvl2 integrated into two-layer palmer model\n",
    "SMOS = ee.ImageCollection('NASA_USDA/HSL/soil_moisture')\n",
    "surface_moisture = SMOS.select('ssm') #units mm, min=0 max=25\n",
    "subsurface_moisture = SMOS.select('susm') #units: mm min=0, max=275\n",
    "moisture_profile = SMOS.select('smp') #units: fraction, min0, max 1\n",
    "\n",
    "#NASA-USDA SMAP Global Soil Moisture Data / 3 days / 2015 - 2019 / 0.25 arc degrees / SMAP level 3 + two-layer Palmer\n",
    "SMAP = ee.ImageCollection('NASA_USDA/HSL/SMAP_soil_moisture')\n",
    "\n",
    "#GLDAS-2.1: Global Land Data Assimilation System / 3 hours / 0.25 arc degrees / 2000 - 2019 / "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLDAS-2.1: Global Land Data Assimilation System \n",
    "Global Land Data Assimilation System (GLDAS) ingests satellite and ground-based observational data products. Using advanced land surface modeling and data assimilation techniques, it generates optimal fields of land surface states and fluxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLDAS = ee.ImageCollection('NASA/GLDAS/V021/NOAH/G025/T3H')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentinel1 derives soil-moisture\n",
    "[Table of content](#Table-of-content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentinel 1 backscatter raw data convertet to reflectivity range between 0 and 1 indicator for high reflectivity = high water volume content and vis verse \n",
    "#Load Sentinel 1 and filter data\n",
    "def load_dataset(ImageCollection_ID,begin,end,aoi):\n",
    "    ic = ee.ImageCollection(ImageCollection_ID).filterDate(begin,end).filterBounds(aoi)\n",
    "    return ic\n",
    "\n",
    "def filter_sentinel1(ImageCollection,polarisation,instrumentMode,resolution):\n",
    "    ic = ImageCollection.filter(ee.Filter.listContains('transmitterReceiverPolarisation',polarisation)).filter(ee.Filter.eq('instrumentMode',instrumentMode)).filterMetadata('resolution_meters','equals', resolution)\n",
    "    return ic\n",
    "\n",
    "def seperate_look_angels(ImageCollection):\n",
    "    Ascending = ImageCollection.filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING'))\n",
    "    Descending = ImageCollection.filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING'))\n",
    "    return Ascending,Descending\n",
    "\n",
    "def seperate_tiles(ImageCollection,tiles):\n",
    "    tile_list = [x]\n",
    "\n",
    "def get_geometry(ImageCollection):\n",
    "    geometry = ImageCollection.geometry().getInfo()\n",
    "    #geometry = [x for x in geometry['coordinates']]\n",
    "    return geometry\n",
    "\n",
    "def show_tiles(ImageCollection):\n",
    "    geometry = get_geometry(ImageCollection)\n",
    "    geometry_list = list(geometry['coordinates'])\n",
    "    flattened_list = [y for x in geometry_list for y in x] #De flatter list \n",
    "    unique_list = []\n",
    "    unique_list = [x for x in flattened_list if x not in unique_list]\n",
    "    print(\"different tiles: \",len(unique_list))\n",
    "    m = Map(center=(49.6252978589571, 8.34580993652344), zoom=7)\n",
    "    geo_json = GeoJSON(data=geometry, style = {'color': 'green', 'opacity':1, 'weight':1.9, 'dashArray':'9', 'fillOpacity':0.1})\n",
    "    m.add_layer(geo_json)\n",
    "    dc = ipyleaflet.DrawControl()\n",
    "    m.add_control(dc)\n",
    "    m.add_control(LayersControl())\n",
    "    return m\n",
    "    \n",
    "def get_properties(ImageCollection):\n",
    "    features = ImageCollection.getInfo()['features']\n",
    "    dict_list = []\n",
    "    for f in features:\n",
    "        prop = f['properties']\n",
    "        dict_list.append(prop)\n",
    "    df = pd.DataFrame.from_records(dict_list).drop(['system:footprint','transmitterReceiverPolarisation'],axis=1)\n",
    "    #Pandas Series of unique distinc values in df\n",
    "    unique = df.nunique()\n",
    "    im_id_list = [item.get('id') for item in ImageCollection.getInfo().get('features')]\n",
    "    date_list = [datetime.datetime.strptime(x[35:43],'%Y%m%d') for x in im_id_list]\n",
    "    #property_names = list(df.columns.values) \n",
    "    return unique, im_id_list, date_list\n",
    "\n",
    "def make_mosaic(date,ImageCollection):\n",
    "    date = ee.Date(date['value'])\n",
    "    filterCollection = ImageCollection.filterDate(date, date.advance(1,'day'))\n",
    "    #Make the mosaic\n",
    "    image = ee.Image(filterCollection.mosaic()).copyProperties(filterCollection.first(),[\"system:time_start\"])\n",
    "    #Add the mosaic to a list only if the collection has images\n",
    "    #return ee.List(ee.Algorithms.If(filterCollection.size(), newList.add(image), newList))\n",
    "    return image\n",
    "\n",
    "def clip_aoi(ImageCollection):\n",
    "    im = ImageCollection.clip(ried_225_222)\n",
    "    return im\n",
    "\n",
    "def add_area(image):\n",
    "    area = image.multiply(ee.Image.pixelArea()).divide(-(1000*1000))\n",
    "    stat = area.reduceRegion(ee.Reducer.sum(),ried_225_222,10) \n",
    "    im = image.set('area',stat.get('VV'))\n",
    "    return im\n",
    "\n",
    "def reproject(image):\n",
    "    VV = image.select('VV')\n",
    "    return image.reporject({crs: VV.projection().crs(), scale : 100})\n",
    "\n",
    "def toNatural(image):\n",
    "    return ee.Image(10.0).pow(image.select(0).divide(10.0)).copyProperties(image)\n",
    "\n",
    "def toDB(image):\n",
    "    return ee.Image(image).log10().multiply(10.0).copyProperties(image)\n",
    "\n",
    "#Sigma Lee speckle filteringThe RL speckle filter from https://code.earthengine.google.com/2ef38463ebaf5ae133a478f173fd0ab5 by Guido Lemoine\n",
    "def RefinedLee(img):\n",
    "    #img must be in natural units, i.e. not in dB!\n",
    "    #Set up 3x3 kernels\n",
    "    weights3 = ee.List.repeat(ee.List.repeat(1,3),3)\n",
    "    kernel3 = ee.Kernel.fixed(3,3, weights3, 1, 1, False)\n",
    "    mean3 = img.reduceNeighborhood(ee.Reducer.mean(), kernel3)\n",
    "    variance3 = img.reduceNeighborhood(ee.Reducer.variance(), kernel3)\n",
    "    #Use a sample of the 3x3 windows inside a 7x7 windows to determine gradients and directions\n",
    "    sample_weights = ee.List([[0,0,0,0,0,0,0], [0,1,0,1,0,1,0],[0,0,0,0,0,0,0], [0,1,0,1,0,1,0], [0,0,0,0,0,0,0], [0,1,0,1,0,1,0],[0,0,0,0,0,0,0]])\n",
    "    sample_kernel = ee.Kernel.fixed(7,7, sample_weights, 3,3, False)\n",
    "    #Calculate mean and variance for the sampled windows and store as 9 bands\n",
    "    sample_mean = mean3.neighborhoodToBands(sample_kernel)\n",
    "    sample_var = variance3.neighborhoodToBands(sample_kernel)\n",
    "    #Determine the 4 gradients for the sampled windows\n",
    "    gradients = sample_mean.select(1).subtract(sample_mean.select(7)).abs()\n",
    "    gradients = gradients.addBands(sample_mean.select(6).subtract(sample_mean.select(2)).abs())\n",
    "    gradients = gradients.addBands(sample_mean.select(3).subtract(sample_mean.select(5)).abs())\n",
    "    gradients = gradients.addBands(sample_mean.select(0).subtract(sample_mean.select(8)).abs())\n",
    "    #And find the maximum gradient amongst gradient bands\n",
    "    max_gradient = gradients.reduce(ee.Reducer.max())\n",
    "    #Create a mask for band pixels that are the maximum gradient\n",
    "    gradmask = gradients.eq(max_gradient)\n",
    "    #duplicate gradmask bands: each gradient represents 2 directions\n",
    "    gradmask = gradmask.addBands(gradmask)\n",
    "    #Determine the 8 directions\n",
    "    directions = sample_mean.select(1).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(7))).multiply(1)\n",
    "    directions = directions.addBands(sample_mean.select(6).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(2))).multiply(2))\n",
    "    directions = directions.addBands(sample_mean.select(3).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(5))).multiply(3))\n",
    "    directions = directions.addBands(sample_mean.select(0).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(8))).multiply(4))\n",
    "    #The next 4 are the not() of the previous 4\n",
    "    directions = directions.addBands(directions.select(0).Not().multiply(5))\n",
    "    directions = directions.addBands(directions.select(1).Not().multiply(6))\n",
    "    directions = directions.addBands(directions.select(2).Not().multiply(7))\n",
    "    directions = directions.addBands(directions.select(3).Not().multiply(8))\n",
    "    #Mask all values that are not 1-8\n",
    "    directions = directions.updateMask(gradmask)\n",
    "    #\"collapse\" the stack into a singe band image (due to masking, each pixel has just one value (1-8) in it's directional band, and is otherwise masked)\n",
    "    directions = directions.reduce(ee.Reducer.sum())\n",
    "    #Generate stats\n",
    "    sample_stats = sample_var.divide(sample_mean.multiply(sample_mean))\n",
    "    #Calculate localNoiseVariance\n",
    "    sigmaV = sample_stats.toArray().arraySort().arraySlice(0,0,5).arrayReduce(ee.Reducer.mean(), [0])\n",
    "    #Set up the 7*7 kernels for directional statistics\n",
    "    rect_weights = ee.List.repeat(ee.List.repeat(0,7),3).cat(ee.List.repeat(ee.List.repeat(1,7),4))\n",
    "    #Set weights\n",
    "    diag_weights = ee.List([[1,0,0,0,0,0,0], [1,1,0,0,0,0,0], [1,1,1,0,0,0,0],[1,1,1,1,0,0,0], [1,1,1,1,1,0,0], [1,1,1,1,1,1,0], [1,1,1,1,1,1,1]])\n",
    "    rect_kernel = ee.Kernel.fixed(7,7, rect_weights, 3, 3, False)\n",
    "    diag_kernel = ee.Kernel.fixed(7,7, diag_weights, 3, 3, False)\n",
    "    #Create stacks for mean and variance using the original kernels Mask with relevant direction.\n",
    "    dir_mean = img.reduceNeighborhood(ee.Reducer.mean(), rect_kernel).updateMask(directions.eq(1))\n",
    "    dir_var = img.reduceNeighborhood(ee.Reducer.variance(), rect_kernel).updateMask(directions.eq(1))\n",
    "    dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(),diag_kernel).updateMask(directions.eq(2)))\n",
    "    dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(),diag_kernel).updateMask(directions.eq(2)))\n",
    "    #and add the bands for rotated kernels\n",
    "    for i in range(4):\n",
    "        dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(),rect_kernel.rotate(i)).updateMask(directions.eq(2*i+1)))\n",
    "        dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(),rect_kernel.rotate(i)).updateMask(directions.eq(2*i+1)))\n",
    "        dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(),diag_kernel.rotate(i)).updateMask(directions.eq(2*i+2)))\n",
    "        dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(),diag_kernel.rotate(i)).updateMask(directions.eq(2*i+2)))\n",
    "    #\"collapse\" the stack into a single band image (due to masking, each pixel has just one value in it's directional band, and is otherwise masked)\n",
    "    dir_mean = dir_mean.reduce(ee.Reducer.sum())\n",
    "    dir_var = dir_var.reduce(ee.Reducer.sum())\n",
    "    #A finally generate the filtered value\n",
    "    varX = dir_var.subtract(dir_mean.multiply(dir_mean).multiply(sigmaV)).divide(sigmaV.add(1.0))\n",
    "    b = varX.divide(dir_var)\n",
    "    result = dir_mean.add(b.multiply(img.subtract(dir_mean)))\n",
    "    return result.arrayFlatten([['VV']]).copyProperties(img)\n",
    "\n",
    "def calc_asc_soilMoisture(image):\n",
    "    im = image.expression('(omega - omegaD) / (omegaW - omegaD)', {'omega' : image.select('VV'), 'omegaD' : minMax_asc.select('VV_max'), 'omegaW' : minMax_asc.select('VV_min')})\n",
    "    return im.addBands(im).select(['VV','VV_1'],['Backscatter_Coefficient','soil_moisture_content'])\n",
    "\n",
    "def calc_des_soilMoisture(image):\n",
    "    im = image.expression('(omega - omegaD) / (omegaW - omegaD)', {'omega' : image.select('VV'), 'omegaD' : minMax_des.select('VV_max'), 'omegaW' : minMax_des.select('VV_min')})\n",
    "    return im.addBands(im).select(['VV','VV_1'],['Backscatter_Coefficient','soil_moisture_content'])\n",
    "\n",
    "def filter_IC(ImageCollection,filter):\n",
    "    old_size = ImageCollection.size().getInfo()\n",
    "    new_coll = ImageCollection.filter(filter)\n",
    "    new_size = new_coll.size().getInfo()\n",
    "    return new_coll\n",
    "\n",
    "def reducer(ImageCollection,reducer):\n",
    "    im = ImageCollection.reduce(reducer)\n",
    "    return im\n",
    "\n",
    "def plot_image(ImageCollection):\n",
    "    m = Map(center=(49.6252978589571, 8.34580993652344), zoom=7)\n",
    "    ic = GetTileLayerUrl(ImageCollection.first().visualize())\n",
    "    m.add_layer(ic)\n",
    "    dc = ipyleaflet.DrawControl()\n",
    "    m.add_control(dc)\n",
    "    m.add_control(LayersControl())\n",
    "    return m\n",
    "\n",
    "def windy_days_filter(image):\n",
    "    d = image.date().format('Y-M-d')\n",
    "    wx = ee.ImageCollection('NOAA/CFSV2/FOR6H')\n",
    "    vWind = wx.select(['v-component_of_wind_height_above_ground'])\n",
    "    a = vWind.max()\n",
    "    uWind = wx.select(['u-component_of_wind_height_above_ground'])\n",
    "    b = uWind.max()\n",
    "    a = a.pow(2)\n",
    "    b = b.pow(2)\n",
    "    ab = a.add(b)\n",
    "    ws = ab.sqrt()\n",
    "    ws = ws.multiply(3.6)\n",
    "    return image.updateMask(ws.lt(12))\n",
    "\n",
    "#Time of interest\n",
    "begin = ee.Date.fromYMD(2013,1,1)\n",
    "end = ee.Date.fromYMD(2019,6,1)\n",
    "date_range = end.difference(begin, 'day')\n",
    "\n",
    "#Source dataset\n",
    "sentinel1 = load_dataset('COPERNICUS/S1_GRD',begin,end,ried_225_222)\n",
    "print(\"sentinel1\",type(sentinel1),\"Collection Size: \", sentinel1.size().getInfo())\n",
    "\n",
    "#Filter dataset for High resolution and Vertical transmitt vertical receive\n",
    "sentinel1_VV = filter_sentinel1(sentinel1,'VV','IW',10)\n",
    "print(\"sentinel1_VV\",type(sentinel1_VV),\"Collection Size: \", sentinel1_VV.size().getInfo())\n",
    "\n",
    "print(sentinel1_VV.first().propertyNames().getInfo())\n",
    "#The RL speckle filter from https://code.earthengine.google.com/2ef38463ebaf5ae133a478f173fd0ab5 by Guido Lemoine\n",
    "sentinel1_VV_natural = sentinel1_VV.map(toNatural)\n",
    "#print(sentinel1_VV_natural.first().propertyNames().getInfo())\n",
    "sentinel1_VV_slFilter = sentinel1_VV_natural.map(RefinedLee)\n",
    "#print(sentinel1_VV_slFilter.first().propertyNames().getInfo())                      \n",
    "sentinel1_VV = sentinel1_VV_slFilter.map(toDB)\n",
    "#print(sentinel1_VV.first().bandNames().getInfo())\n",
    "#print(sentinel1_VV.first().propertyNames().getInfo())\n",
    "\n",
    "#Filter for different look angles\n",
    "VV_Ascending,VV_Descending = seperate_look_angels(sentinel1_VV)\n",
    "print(\"VV_Ascending\",type(VV_Ascending),\"VV_Descending\",type(VV_Descending),\"Collection Size: \", VV_Ascending.size().getInfo(), VV_Descending.size().getInfo())\n",
    "\n",
    "#Clip images to AOI and calculate area property\n",
    "VV_aoi_asc = VV_Ascending.map(clip_aoi).map(add_area)\n",
    "print(\"VV_aoi_asc\",type(VV_aoi_asc),\"Collection Size: \", VV_aoi_asc.size().getInfo())\n",
    "VV_aoi_des = VV_Descending.map(clip_aoi).map(add_area)\n",
    "print(\"VV_aoi_des\",type(VV_aoi_des),\"Collection Size: \", VV_aoi_des.size().getInfo())\n",
    "\n",
    "#Create Min and Max bands for change detection method\n",
    "minMax_asc = reducer(VV_aoi_asc,ee.Reducer.minMax())\n",
    "print(\"minMax_asc\",type(minMax_asc),minMax_asc.getInfo())\n",
    "minMax_des = reducer(VV_aoi_des,ee.Reducer.minMax())\n",
    "print(\"minMax_des\",type(minMax_des),minMax_des.getInfo())\n",
    "\n",
    "#Compute soil moisture with simple change detection Methode\n",
    "VV_asc_sm = VV_aoi_asc.map(calc_asc_soilMoisture)\n",
    "print(\"VV_asc_sm\",type(VV_asc_sm),\"Collection Size: \", VV_asc_sm.size().getInfo())\n",
    "VV_des_sm = VV_aoi_des.map(calc_des_soilMoisture)\n",
    "print(\"VV_des_sm\",type(VV_des_sm),\"Collection Size: \", VV_des_sm.size().getInfo())\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#Get list of ids,dates and unique count of prop\n",
    "unique, im_id_list, date_list = get_properties(VV_Ascending)\n",
    "date_list = ee.List([ee.Date(x) for x in date_list])\n",
    "#pp.pprint(unique)\n",
    "\n",
    "#Improve dataset validity \n",
    "VV_aoi_filtered = filter_IC(VV_aoi_area,ee.Filter.gte('area',250))\n",
    "print(\"VV_aoi_filtered\",type(VV_aoi_filtered),\"Collection Size: \", VV_aoi_filtered.size().getInfo())\n",
    "\n",
    "pp.pprint(VV_des_sm.getInfo().get('features')[1])\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get CSV for Datasets\n",
    "[Table of content](#Table-of-content)  \n",
    "Only year by year otherwise memory exceeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = ee.Geometry.Polygon([[[8.492535113992176,49.806727648654025],[8.474855734199537,49.8022389698566],[8.529615838732752,49.758455050463446],[8.562403236731484,49.777747019690885],[8.518286161973151,49.805895076244035],[8.492535113992176,49.806727648654025]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CSV from SMOS soil-moisture for Ried (1 Polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geometrys, Regions, Source Dataset, TOI, \n",
    "# Function to iterate over image collection, returning a pandas dataframe\n",
    "start,end = datetime.datetime(2014,1,1),datetime.datetime(2020,1,1)\n",
    "sm = SMOS.filterDate(start,end)\n",
    "\n",
    "def extract_point_values(img_id):\n",
    "    IC = sm.filter(ee.Filter.eq('system:index',img_id))\n",
    "    image = IC.reduce(ee.Reducer.first())\n",
    "    #Ad reducer output to the Features in the collection.\n",
    "    #projection = im.projection().getInfo()['crs']\n",
    "    im_reduce = image.reduceRegion(ee.Reducer.mean(),aoi, scale = 100) #,scale=1000\n",
    "    # Convert to Pandas Dataframe\n",
    "    data_aoi = im_reduce.getInfo()\n",
    "    df = pd.DataFrame.from_records([data_aoi])\n",
    "    return df\n",
    "\n",
    "#List of image propertys \n",
    "im_prop = sm.first().propertyNames().getInfo()\n",
    "#Get propertie from every image to a List\n",
    "im_id = [item['properties']['system:index'] for item in sm.getInfo().get('features')]\n",
    "im_date = [datetime.datetime.strptime(x[12:20],'%Y%m%d') for x in im_id] #http://joda-time.sourceforge.net/apidocs/org/joda/time/format/DateTimeFormat.html\n",
    "\n",
    "#### Create Initial Pandas Dataframe\n",
    "df_all = extract_point_values(im_id[0])\n",
    "df_all = df_all.drop([0])\n",
    "\n",
    "#### Iterate over all impages\n",
    "for i in im_id:\n",
    "    df_all = df_all.append(extract_point_values(i))\n",
    "\n",
    "#Set date and save a lot of .getInfo() calls\n",
    "df_all['date'] = im_date\n",
    "\n",
    "df_all.to_csv(\"SMOS_testGeometry.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CSV for S1 derives Soil Moisture and Backscatter Signal for Ried (1 Polygon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To-D:  \n",
    "Backscatter Coefficient ist gleich dem content der Bodenfeuchte?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geometrys, Regions, Source Dataset, TOI, \n",
    "# Function to iterate over image collection, returning a pandas dataframe\n",
    "sm = VV_asc_sm\n",
    "def extract_point_values(img_id):\n",
    "    IC = sm.filter(ee.Filter.eq('system:index',img_id))\n",
    "    image = IC.reduce(ee.Reducer.first())\n",
    "    #Ad reducer output to the Features in the collection.\n",
    "    #projection = im.projection().getInfo()['crs']\n",
    "    im_reduce = image.reduceRegion(ee.Reducer.mean(),aoi, scale = 100) #,scale=1000\n",
    "    # Convert to Pandas Dataframe\n",
    "    data_aoi = im_reduce.getInfo()\n",
    "    df = pd.DataFrame.from_records([data_aoi])\n",
    "    return df\n",
    "\n",
    "#List of image propertys \n",
    "im_prop = sm.first().propertyNames().getInfo()\n",
    "#Get propertie from every image to a List\n",
    "im_id = [item['properties']['system:index'] for item in sm.getInfo().get('features')]\n",
    "im_date = [datetime.datetime.strptime(x[33:48],'%Y%m%dT%H%M%S') for x in im_id] #http://joda-time.sourceforge.net/apidocs/org/joda/time/format/DateTimeFormat.html\n",
    "\n",
    "#### Create Initial Pandas Dataframe\n",
    "df_all = extract_point_values(im_id[0])\n",
    "df_all = df_all.drop([0])\n",
    "\n",
    "#### Iterate over all impages\n",
    "for i in im_id:\n",
    "    df_all = df_all.append(extract_point_values(i))\n",
    "\n",
    "#Set date and save a lot of .getInfo() calls\n",
    "df_all['date'] = im_date\n",
    "\n",
    "df_all.to_csv(\"S1_asc_100_testGeometry_LF.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CSV for Chrisp derived precipitation for Ried (1 Polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geometrys, Regions, Source Dataset, TOI, \n",
    "start,end = datetime.datetime(2014,1,1),datetime.datetime(2020,1,1)\n",
    "#aoi = ried\n",
    "sm = chirps.filterDate(start,end)\n",
    "\n",
    "# Function to iterate over image collection, returning a pandas dataframe\n",
    "def extract_point_values(img_id, aoi):\n",
    "    image = ee.Image(img_id)\n",
    "    #Ad reducer output to the Features in the collection.\n",
    "    fc_image_red = image.reduceRegion(ee.Reducer.mean(), aoi) #,scale=1000\n",
    "    # Convert to Pandas Dataframe\n",
    "    data_aoi = fc_image_red.getInfo()\n",
    "    data_aoi['geometry'] = aoi.getInfo()['features']\n",
    "    data_aoi['date'] = datetime.datetime.strptime(image.getInfo()['id'][22:31],'%Y%m%d')\n",
    "    df = pd.DataFrame(data_aoi)\n",
    "    return df\n",
    "\n",
    "#List of image propertys \n",
    "im_prop = sm.first().propertyNames().getInfo()\n",
    "#Get propertie from every image to a List\n",
    "im_id = [item.get('id') for item in sm.getInfo().get('features')]\n",
    "\n",
    "#### Create Initial Pandas Dataframe\n",
    "df_all = extract_point_values(im_id[0], aoi)\n",
    "df_all = df_all.drop([0])\n",
    "\n",
    "#### Iterate over all impages\n",
    "for i in im_id:\n",
    "    df_all = df_all.append(extract_point_values(i, aoi))\n",
    "df_all.to_csv(\"chirps_testGeometry.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geometrys, Regions, Source Dataset, TOI, \n",
    "# Function to iterate over image collection, returning a pandas dataframe\n",
    "start,end = datetime.datetime(2014,1,1),datetime.datetime(2020,1,1)\n",
    "sm = chirps.filterDate(start,end)\n",
    "\n",
    "def extract_point_values(img_id):\n",
    "    IC = sm.filter(ee.Filter.eq('system:index',img_id))\n",
    "    image = IC.reduce(ee.Reducer.first())\n",
    "    #Ad reducer output to the Features in the collection.\n",
    "    #projection = im.projection().getInfo()['crs']\n",
    "    im_reduce = image.reduceRegion(ee.Reducer.mean(),aoi, scale = 100) #,scale=1000\n",
    "    # Convert to Pandas Dataframe\n",
    "    data_aoi = im_reduce.getInfo()\n",
    "    df = pd.DataFrame.from_records([data_aoi])\n",
    "    return df\n",
    "\n",
    "#List of image propertys \n",
    "im_prop = sm.first().propertyNames().getInfo()\n",
    "#Get propertie from every image to a List\n",
    "im_id = [item['properties']['system:index'] for item in sm.getInfo().get('features')]\n",
    "im_date = [datetime.datetime.strptime(x[0:8],'%Y%m%d') for x in im_id] #http://joda-time.sourceforge.net/apidocs/org/joda/time/format/DateTimeFormat.html\n",
    "\n",
    "#### Create Initial Pandas Dataframe\n",
    "df_all = extract_point_values(im_id[0])\n",
    "df_all = df_all.drop([0])\n",
    "\n",
    "#### Iterate over all impages\n",
    "for i in im_id:\n",
    "    df_all = df_all.append(extract_point_values(i))\n",
    "\n",
    "#Set date and save a lot of .getInfo() calls\n",
    "df_all['date'] = im_date\n",
    "\n",
    "df_all.to_csv(\"SMOS_testGeometry.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CSV for GLDAS climate values for Ried (1 Polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geometrys, Regions, Source Dataset, TOI, \n",
    "start,end = datetime.datetime(2014,1,1),datetime.datetime(2020,1,1)\n",
    "#aoi = ried\n",
    "sm = GLDAS.filterDate(start,end)\n",
    "\n",
    "# Function to iterate over image collection, returning a pandas dataframe\n",
    "def extract_point_values(img_id, aoi):\n",
    "    image = ee.Image(img_id)\n",
    "    #Ad reducer output to the Features in the collection.\n",
    "    fc_image_red = image.reduceRegion(ee.Reducer.mean(), aoi) #,scale=1000\n",
    "    # Convert to Pandas Dataframe\n",
    "    data_aoi = fc_image_red.getInfo()\n",
    "    #data_aoi['date'] = datetime.datetime.strptime(image.getInfo()['id'][31:39],'%Y%m%d')\n",
    "    #df = pd.DataFrame(data_aoi,columns=['Albedo_inst', 'AvgSurfT_inst', 'CanopInt_inst', 'ECanop_tavg', 'ESoil_tavg', 'Evap_tavg', 'LWdown_f_tavg', 'Lwnet_tavg', 'PotEvap_tavg', 'Psurf_f_inst', 'Qair_f_inst', 'Qg_tavg', 'Qh_tavg', 'Qle_tavg', 'Qs_acc', 'Qsb_acc', 'Qsm_acc', 'Rainf_f_tavg', 'Rainf_tavg', 'RootMoist_inst', 'SWE_inst', 'SWdown_f_tavg', 'SnowDepth_inst', 'Snowf_tavg', 'SoilMoi0_10cm_inst', 'SoilMoi100_200cm_inst', 'SoilMoi10_40cm_inst', 'SoilMoi40_100cm_inst', 'SoilTMP0_10cm_inst', 'SoilTMP100_200cm_inst', 'SoilTMP10_40cm_inst', 'SoilTMP40_100cm_inst', 'Swnet_tavg', 'Tair_f_inst', 'Tveg_tavg', 'Wind_f_inst'])\n",
    "    df = pd.DataFrame.from_records([data_aoi])\n",
    "    return df\n",
    "\n",
    "#List of image propertys \n",
    "im_prop = sm.first().propertyNames().getInfo()\n",
    "#Get propertie from every image to a List\n",
    "im_id = [item.get('id') for item in sm.getInfo().get('features')]\n",
    "im_date = [datetime.datetime.strptime(x[31:44],'%Y%m%d_%H%M') for x in im_id]\n",
    "\n",
    "#### Create Initial Pandas Dataframe\n",
    "df_all = extract_point_values(im_id[0], aoi)\n",
    "df_all = df_all.drop([0])\n",
    "\n",
    "#### Iterate over all impages\n",
    "for i in im_id:\n",
    "    df_all = df_all.append(extract_point_values(i, aoi))\n",
    "\n",
    "#Set date and save a lot of .getInfo() calls\n",
    "df_all['date'] = im_date\n",
    "\n",
    "df_all.to_csv(\"GLDAS_testGeometry.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geometrys, Regions, Source Dataset, TOI, \n",
    "# Function to iterate over image collection, returning a pandas dataframe\n",
    "start,end = datetime.datetime(2014,1,1),datetime.datetime(2020,1,1)\n",
    "sm = GLDAS.filterDate(start,end).filterMetadata('start_hour', 'equals', 18) #Daten für 18 Uhr if not than you have more than 5000 Elements\n",
    "\n",
    "def extract_point_values(img_id):\n",
    "    IC = sm.filter(ee.Filter.eq('system:index',img_id))\n",
    "    image = IC.reduce(ee.Reducer.first())\n",
    "    #Ad reducer output to the Features in the collection.\n",
    "    #projection = im.projection().getInfo()['crs']\n",
    "    im_reduce = image.reduceRegion(ee.Reducer.mean(),aoi, scale = 100) #,scale=1000\n",
    "    # Convert to Pandas Dataframe\n",
    "    data_aoi = im_reduce.getInfo()\n",
    "    df = pd.DataFrame.from_records([data_aoi])\n",
    "    return df\n",
    "\n",
    "#List of image propertys \n",
    "im_prop = sm.first().propertyNames().getInfo()\n",
    "#Get propertie from every image to a List\n",
    "im_id = [item['properties']['system:index'] for item in sm.getInfo().get('features')]\n",
    "#print(im_id)\n",
    "im_date = [datetime.datetime.strptime(x[1:12],'%Y%m%d_%H') for x in im_id] #http://joda-time.sourceforge.net/apidocs/org/joda/time/format/DateTimeFormat.html\n",
    "\n",
    "#### Create Initial Pandas Dataframe\n",
    "df_all = extract_point_values(im_id[0])\n",
    "df_all = df_all.drop([0])\n",
    "\n",
    "#### Iterate over all impages\n",
    "for i in im_id:\n",
    "    df_all = df_all.append(extract_point_values(i))\n",
    "\n",
    "#Set date and save a lot of .getInfo() calls\n",
    "df_all['date'] = im_date\n",
    "\n",
    "df_all.to_csv(\"GLDAS_testGeometry.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualisation  \n",
    "[Table of content](#Table-of-content)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get TileLayerurl from ee to plot on ipyleaflet\n",
    "def GetTileLayerUrl(ee_image_object):\n",
    "    map_id = ee.Image(ee_image_object).getMapId()\n",
    "    tile_url_template = \"https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}\"\n",
    "    return tile_url_template.format(**map_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization Parameters\n",
    "dark_matter_layer = basemap_to_tiles(basemaps.CartoDB.DarkMatter)\n",
    "germany_viz = GetTileLayerUrl(germany_outline.visualize())\n",
    "#radolan_viz = GetTileLayerUrl(radolan.visualize(min=0,max=40,bands=['b1']))\n",
    "clc_viz = GetTileLayerUrl(clc.visualize(min=0,max=7,palette=['FFE6FF','FFFFA8','FFFF00','E6E600','E68000','F2A64D','E6A600']))\n",
    "#clc_vector_viz = GetTileLayerUrl(clc_vector.draw(color='red').visualize())\n",
    "#surface_moisture_viz = GetTileLayerUrl(surface_moisture.visualize(min=0,max=28,palette=['0300ff', '418504', 'efff07', 'efff07', 'ff0303']))\n",
    "#random_points_viz = GetTileLayerUrl(random_points.draw(color='blue').visualize())\n",
    "#sentinel1_viz = GetTileLayerUrl(newcol.first().visualize())\n",
    "\n",
    "# Create layer group\n",
    "layer_group = LayerGroup(layers=(ipyleaflet.TileLayer(url=clc_viz,name='Corine Land Cover 2012'),\n",
    "                                 ipyleaflet.TileLayer(url=germany_viz, name='german boundary'),\n",
    "                                 #ipyleaflet.TileLayer(url=clc_vector_viz, name='clc_vector')\n",
    "                                 #ipyleaflet.TileLayer(url=random_points_viz, name='rand point')\n",
    "                                 #ipyleaflet.TileLayer(url=surface_moisture_viz, name='GSMD surface moisture')\n",
    "                                ))\n",
    "#Map options\n",
    "center,zoom = (49.6252978589571, 8.34580993652344),11\n",
    "\n",
    "#Interactive Visualizations\n",
    "map1 = ipyleaflet.Map(layer= dark_matter_layer, center=center, zoom=zoom, layout={'height' : '600px'})\n",
    "dc = ipyleaflet.DrawControl()\n",
    "map1.add_control(dc)\n",
    "map1.add_layer(layer_group)\n",
    "map1.add_control(LayersControl())\n",
    "map1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Coordinates from Drawn Geometry\n",
    "dc.last_draw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collection of commands   \n",
    "[Table of content](#table-of-content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Command Collection\n",
    ".size().getInfo() # Get collection size\n",
    ".bandNames().getInfo() # Get List with alls Bands from ee.Image not ImageCollection\n",
    ".geometry().bounds().getInfo() # get Geometry of a Feature // Get bounding box of this geometry\n",
    ".limit(5000) # Limit to the first 5000 Elements/Features\n",
    ".normalizedDifference(bandNames) #(first − second) / (first + second) Indice\n",
    "image.addBands(ndvi).rename(image.bandNames().add('NDVI')) #add band to the image and rename it correctly\n",
    "\n",
    "#Vectorizing\n",
    "var vectors = image.reduceToVectors({\n",
    "  geometry: FeatureCollection,\n",
    "  crs: image.projection(),\n",
    "  scale: 1000,\n",
    "  geometryType: 'polygon',\n",
    "  eightConnected: false,\n",
    "  labelProperty: 'zone',\n",
    "  reducer: ee.Reducer.mean()\n",
    "});\n",
    "\n",
    "#Masking\n",
    ".clip(feature)\n",
    "var image = ee.Image\n",
    "var mask = image.gte(2).And(lt(5))\n",
    "var maskedImage = image.updateMask(mask)\n",
    "\n",
    "#Visualizations\n",
    "thumbnail_url = image.getThumbUrl({\n",
    "    'bands' : '',\n",
    "    'min' : ,\n",
    "    'max' : ,\n",
    "    'region' : .geometry().bounds().getInfo() #must be a geojson \n",
    "})\n",
    "IPython.display.HTML('Thumnail URL: <a href={0}>{0}</a>'.format(thumbnail_url)) #create url to view\n",
    "IPython.display.Image(url=thumbnail_url) # view direct in notebook\n",
    "\n",
    "#Interactive Visualizations\n",
    "import ipyleaflet\n",
    "map1 = ipyleaflet.Map(zoom=3, layout={'height' : '400px'})\n",
    "dc = ipyleaflet.DrawControl()\n",
    "map1.add_control(dc)\n",
    "map1\n",
    "dc.last_draw # gives information about the last drawn polygon (coordinates etc.)\n",
    "\n",
    "#Function to create a tile layer urlfrom an gee image object\n",
    "def GetTileLayerUrl(ee_image_object):\n",
    "    map_id = ee.Image(ee_image_object).getMapId()\n",
    "    tile_url_template = \"https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}\"\n",
    "    return tile_url_template.format(**map_id)\n",
    "\n",
    "#style the image\n",
    "tile_url = GetTileLayerUrl(image.visualize(min=0, max=3000, gamma=1.5, bands=['','','']))\n",
    "map1.add_layer(ipyleaflet.TileLayer(url=tile_url))\n",
    "#or create layer groups "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collection of Notebook snippets \n",
    "[Table of content](#Table-of-content)  \n",
    "for getting pandas DataFrame of AOI Time Series Satellite Data from GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geometrys, Regions\n",
    "points = ee.FeatureCollection([\n",
    "            ee.Feature(ee.Geometry.Point(8.234870250943459,49.80831604635797)),\n",
    "            ee.Feature(ee.Geometry.Point(8.241221721890724,49.6585087644599)),\n",
    "            ])\n",
    "point = ee.Feature(ee.Geometry.Point(8.234870250943459,49.80831604635797))\n",
    "\n",
    "#Time\n",
    "start,end = datetime.datetime(2015,1,1),datetime.datetime(2016,1,1)\n",
    "#Source Dataset\n",
    "chirps = chirps_precipitation.filterDate(start,end)\n",
    "# Function Convert a FeatureCollection into a pandas DataFrame; Features is a list of dict with the output\n",
    "def fc2df(fc):\n",
    "    # Convert a FeatureCollection into a pandas DataFrame\n",
    "    # Features is a list of dict with the output\n",
    "    features = fc.getInfo()['features']\n",
    "\n",
    "    dictarr = []\n",
    "    for f in features:\n",
    "        # Store all attributes in a dict\n",
    "        attr = f['properties']\n",
    "        # and treat geometry separately\n",
    "        attr['geometry'] = f['geometry']  # GeoJSON Feature!\n",
    "        #attr['geometrytype'] = f['geometry']['type']\n",
    "        dictarr.append(attr)\n",
    "\n",
    "    df = gpd.GeoDataFrame(dictarr)\n",
    "    # Convert GeoJSON features to shape\n",
    "    #df['geometry'] = map(lambda x: shape(x), df.geometry)    \n",
    "    return df\n",
    "\n",
    "# Function to iterate over image collection, returning a pandas dataframe\n",
    "def extract_point_values(img_id, pts):\n",
    "    image = ee.Image(img_id)\n",
    "    #Ad reducer output to the Features in the collection.\n",
    "    fc_image_red = image.reduceRegions(collection=pts, reducer=ee.Reducer.mean(), scale=1000)\n",
    "    # Convert to Pandas Dataframe\n",
    "    df_image_red = fc2df(fc_image_red)\n",
    "    # Add Date as Variable\n",
    "    df_image_red['date'] = datetime.datetime.strptime(image.getInfo()['id'][22:31],'%Y%m%d')\n",
    "    print(df_image_red)\n",
    "    return df_image_red\n",
    "\n",
    "#List of image propertys \n",
    "chirps_prop = surface_moisture.first().propertyNames().getInfo()\n",
    "print('Check 1')\n",
    "#Get propertie from every image to a List\n",
    "chirps_id = [] #empty list\n",
    "chirps_id = [item.get('id') for item in chirps.getInfo().get('features')]\n",
    "#### Create Initial Pandas Dataframe\n",
    "df_all = extract_point_values(chirps_id[0], points)\n",
    "df_all = df_all.drop([0,1])\n",
    "print(\"check 3\")\n",
    "#### Iterate over all impages\n",
    "c=0\n",
    "for i in chirps_id:\n",
    "    c = c+ 1\n",
    "    print(\"c\",c)\n",
    "    df_all = df_all.append(extract_point_values(i, points))\n",
    "print(\"check 4\")\n",
    "#### Display Results\n",
    "pp.pprint(df_all)\n",
    "rad_point1 = df_all.loc[0]\n",
    "rad_point2 = df_all.loc[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://gis.stackexchange.com/questions/313186/extracting-pixel-time-series-from-google-earth-engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import ee\n",
    "from ipygee import *\n",
    "\n",
    "\n",
    "def extract_time_series(start,end,coll,ried): #,sf\n",
    "\n",
    "    \n",
    "    # Obtain image collection for all images within query dates\n",
    "    coll = coll.filterDate(start,end)\n",
    "\n",
    "    # Get list of images which correspond with the above\n",
    "    images = [item.get('id') for item in coll.getInfo().get('features')]\n",
    "    store = []\n",
    "    date_store = []\n",
    "    print(images)\n",
    "    # Loop over all images and extract pixel value\n",
    "    for image in images:\n",
    "        \n",
    "        im = ee.Image(image)\n",
    "        #projection = im.projection().getInfo()['crs']\n",
    "        # Obtain date from timestamp in metadata\n",
    "        date = dt.fromtimestamp(im.get(\"system:time_start\").getInfo() / 1000.)\n",
    "        date_store.append(np.datetime64(date))\n",
    "\n",
    "        # Extract pixel value\n",
    "        data = im.reduceRegion(ee.Reducer.mean(),ried, 1000) #,1, crs=projection).get(band_name) \n",
    "        store.append(data.getInfo())\n",
    "        print(store)\n",
    "    # Scale the returned data based on scale factor\n",
    "    #store = [x * sf if isinstance(x, int) else np.nan for x in store]\n",
    "    \n",
    "    # Convert output into pandas data frame\n",
    "    df = pd.DataFrame(index=date_store, data=store, columns=['precipitation'])\n",
    "    df['store']\n",
    "    return df\n",
    "\n",
    "\n",
    "band_name = 'b1'\n",
    "coll = chirps_precipitation\n",
    "start,end = datetime.datetime(2015,1,1),datetime.datetime(2015,1,5)\n",
    "# Set up point geometry\n",
    "points = ee.FeatureCollection([\n",
    "        ee.Feature(ee.Geometry.Point(8.234870250943459,49.80831604635797)),\n",
    "        ee.Feature(ee.Geometry.Point(8.241221721890724,49.6585087644599)),\n",
    "        ])\n",
    "point = ee.Feature(ee.Geometry.Point(8.234870250943459,49.80831604635797))\n",
    "\n",
    "\n",
    "rad_data = extract_time_series(start,end,coll,ried)\n",
    "print(rad_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
