{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T12:32:08.258158Z",
     "start_time": "2022-02-02T12:32:08.226916Z"
    }
   },
   "outputs": [],
   "source": [
    "def mlp_lr_sm(paths, features, y_label,  ):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Import modules\n",
    "    from glob import glob\n",
    "    import datetime as dt\n",
    "    import geopandas as gpd\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    \n",
    "    \n",
    "    ## Initialize data\n",
    "    # Files with data\n",
    "    paths = glob(paths)\n",
    "    paths.sort()\n",
    "\n",
    "    # Create Station id linked with filepath\n",
    "    ids = [x.split('\\\\')[-1].split('_')[0] for x in paths]\n",
    "    files = dict(zip(ids,paths))\n",
    "\n",
    "    # Load all files into one Dataframe\n",
    "    gdf = gpd.tools.util.pd.concat(map(gpd.read_file, paths), ignore_index=True)\n",
    "    print(f'Rows before preprocessing {len(gdf)}')\n",
    "    \n",
    "    \n",
    "    ## Preprocessing\n",
    "    # Set type of date column to datetime object\n",
    "    gdf.date = gdf.date.astype('datetime64[ns]')\n",
    "\n",
    "    # Convert int to timedelta in days\n",
    "    s2_timedelta = [dt.timedelta(days=x) for x in gdf.s2_distance]\n",
    "    gdf.s2_distance = s2_timedelta\n",
    "\n",
    "    #Remove uneseccary columns\n",
    "    gdf.drop(labels = ['CloudMask'], axis = 1, inplace = True)\n",
    "\n",
    "    # Clean Nan Values within subset columns (major variables to inspect)\n",
    "    gdf.dropna(how='any', subset=['soil_moisture', 'VV'], inplace=True)\n",
    "\n",
    "    # Drop lower and upper 1% of data to eliminate outliers\n",
    "    gdf = gdf[gdf.soil_moisture.gt(gdf.soil_moisture.quantile(0.01)) & gdf.soil_moisture.lt(gdf.soil_moisture.quantile(0.99))]\n",
    "    gdf = gdf[gdf.VV.gt(gdf.VV.quantile(0.01)) & gdf.VV.lt(gdf.VV.quantile(0.99))]\n",
    "    gdf = gdf[gdf.NDVI.gt(gdf.NDVI.quantile(0.01)) & gdf.NDVI.lt(gdf.NDVI.quantile(0.99))]\n",
    "\n",
    "    # Remove rows where ndvi is older than 30days\n",
    "    gdf = gdf[gdf.s2_distance.gt(dt.timedelta(days=-7)) & gdf.s2_distance.lt(dt.timedelta(days=7))]\n",
    "\n",
    "    # Select only sm and vv meassurements where soil is not in frozen state\n",
    "    print(f'Rows after preprocessing {len(gdf)}')\n",
    "    \n",
    "    \n",
    "    ## One Hot Encoding\n",
    "    # Drop categorical data \n",
    "    orbit = gdf.pop('orbit')\n",
    "    platform = gdf.pop('platform')\n",
    "    \n",
    "    gdf['ASCENDING'] = (orbit == 'ASCENDING')*1\n",
    "    gdf['DESCENDING'] = (orbit == 'DESCENDING')*1\n",
    "\n",
    "    gdf['Sentinel_A'] = (platform == 'A')*1\n",
    "    gdf['Sentinel_B'] = (platform == 'B')*1\n",
    "    \n",
    "    \n",
    "    ## Statistics\n",
    "    #KDE Plot\n",
    "    plot_kde = sns.pairplot(gdf[features], diag_kind = 'kde')\n",
    "    print(plot_kde)\n",
    "    \n",
    "    # Dataframe Statistics \n",
    "    train_stats = gdf[features].describe()\n",
    "    train_stats.pop(y_label)\n",
    "    train_stats = train_stats.transpose()\n",
    "    print(train_stats)\n",
    "    \n",
    "    \n",
    "    ## Split into Train and Test \n",
    "    df = pd.DataFrame(gdf[features]).reset_index(drop=True)\n",
    "    train_df = df.sample(frac = 0.8, random_state=0)\n",
    "    test_df = df.drop(train_df.index)\n",
    "    \n",
    "    train_labels = train_df.pop(y_label)\n",
    "    test_labels = test_df.pop(y_label)\n",
    "    \n",
    "    ## Normalize data\n",
    "    def norm(x):\n",
    "        return (x - train_stats['mean']) / train_stats['std']\n",
    "    \n",
    "    n_train_df = norm(train_df)\n",
    "    n_test_df = norm(test_df)\n",
    "    \n",
    "    \n",
    "    ## The Model\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras import layers\n",
    "    from tensorflow.nn import relu\n",
    "    from tensorflow.keras.optimizers import RMSprop\n",
    "    from keras.callbacks import Callback\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "    \n",
    "    #Architecture \n",
    "    def build_model():\n",
    "        model = Sequential([\n",
    "            layers.Dense(64, activation=relu, input_shape=[len(n_train_df.keys())]), # densly (fully connected) hidden layer\n",
    "            layers.Dense(64, activation=relu), # denly hidden layer\n",
    "            layers.Dense(1) #output layer\n",
    "        ])\n",
    "\n",
    "        optimizer = RMSprop(0.001)\n",
    "\n",
    "        model.compile(\n",
    "            loss = 'mse', # mean sqared error\n",
    "            optimizer = optimizer,\n",
    "            metrics = ['mae', 'mse']) \n",
    "\n",
    "        return model\n",
    "    \n",
    "    model = build_model()\n",
    "    \n",
    "    #Inspect Model\n",
    "    print(model.summary())\n",
    "    \n",
    "    \n",
    "    ## Train the model\n",
    "    # Callbacks\n",
    "    class Calls(Callback):\n",
    "        #Print dot every epoch while training\n",
    "        def on_epoch_end(self, epoch, logs):\n",
    "            if epoch % 100 == 0: print('')\n",
    "            print('.', end='')\n",
    "\n",
    "    # stop the training when there is no improvement in the loss for three consecutive epochs.\n",
    "    stop_improving = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    \n",
    "    EPOCHS = 1000\n",
    "\n",
    "    history = model.fit(\n",
    "        x = n_train_df,\n",
    "        y = train_labels,\n",
    "        epochs = EPOCHS,\n",
    "        validation_split = 0.2, \n",
    "        verbose = 0,\n",
    "        callbacks = [Calls(), stop_improving])\n",
    "    \n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "    print(hist.tail())\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    def plot_history(hitsory):\n",
    "        hist = pd.DataFrame(history.history)\n",
    "        hist['epoch'] = history.epoch\n",
    "\n",
    "        plt.figure()\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Mean Abs Error [MPG]')\n",
    "        plt.plot(hist['epoch'], hist['mae'],\n",
    "                label = 'Train Error')\n",
    "        plt.plot(hist['epoch'], hist['val_mae'],\n",
    "                label = 'Val Error')\n",
    "        plt.legend()\n",
    "        plt.ylim([0,hist['mae'].max() + hist['mae'].max() * 0.5])\n",
    "\n",
    "        plt.figure()\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Mean Square Error [m^3/m^3^2]')\n",
    "        plt.plot(hist['epoch'], hist['mse'],\n",
    "                label = 'Train Error')\n",
    "        plt.plot(hist['epoch'], hist['val_mse'],\n",
    "                label = 'Val Error')\n",
    "        plt.legend()\n",
    "        plt.ylim([0,hist['mse'].max() + hist['mse'].max() * 0.5])\n",
    "\n",
    "    plot_history(history)\n",
    "    \n",
    "    loss, mae, mse = model.evaluate(n_test_df, test_labels, verbose = 0)\n",
    "    print(\"Testing set Mean Abs Error: {:5.2f} m^3/m^3\".format(mae))\n",
    "    \n",
    "    ## Make Predictions\n",
    "    test_predictions = model.predict(n_test_df).flatten()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(test_labels, test_predictions)\n",
    "    plt.xlabel('True Values m^3/m^3')\n",
    "    plt.ylabel('Predictions m^3/m^3')\n",
    "    plt.axis('equal')\n",
    "    plt.axis('square')\n",
    "    plt.xlim([0,0.5])\n",
    "    plt.ylim([0,0.5])\n",
    "    plot_predict_scatter = plt.plot([-100,100], [-100,100])\n",
    "    print(plot_predict_scatter)\n",
    "    \n",
    "    plt.figure()\n",
    "    error = test_predictions - test_labels\n",
    "    plt.hist(error, bins=25)\n",
    "    plt.xlabel('Prediction Error m^3/m^3')\n",
    "    plot_error_hist = plt.ylabel('Count')\n",
    "    print(plot_error_hist)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T12:32:40.531970Z",
     "start_time": "2022-02-02T12:32:08.280295Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp_lr_sm(\n",
    "    paths = 'C://Users/USER/Desktop/Master_Irrigation/03_GIS/ground_trouth/sentinel_ismn_data/*',\n",
    "    features = ['VV', 'ASCENDING','DESCENDING','Sentinel_A','Sentinel_B', 'soil_moisture'],\n",
    "    y_label = 'soil_moisture'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T12:33:16.776115Z",
     "start_time": "2022-02-02T12:32:40.547582Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp_lr_sm(\n",
    "    paths = 'C://Users/USER/Desktop/Master_Irrigation/03_GIS/ground_trouth/sentinel_ismn_data/*',\n",
    "    features = ['VV', 'ASCENDING','DESCENDING','Sentinel_A','Sentinel_B','NDVI', 'soil_moisture'],\n",
    "    y_label = 'soil_moisture'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T12:34:00.392220Z",
     "start_time": "2022-02-02T12:33:16.791737Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp_lr_sm(\n",
    "    paths = 'C://Users/USER/Desktop/Master_Irrigation/03_GIS/ground_trouth/sentinel_ismn_data/*',\n",
    "    features = ['VV', 'ASCENDING','DESCENDING','Sentinel_A','Sentinel_B','NDVI','angle', 'soil_moisture'],\n",
    "    y_label = 'soil_moisture'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T12:39:52.778278Z",
     "start_time": "2022-02-02T12:38:59.357074Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp_lr_sm(\n",
    "    paths = 'C://Users/USER/Desktop/Master_Irrigation/03_GIS/ground_trouth/sentinel_ismn_data/*',\n",
    "    features = ['VV', 'ASCENDING','DESCENDING','Sentinel_A','Sentinel_B','NDVI','angle','ismn_id', 'soil_moisture'],\n",
    "    y_label = 'soil_moisture'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T12:42:37.929429Z",
     "start_time": "2022-02-02T12:41:43.123453Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp_lr_sm(\n",
    "    paths = 'C://Users/USER/Desktop/Master_Irrigation/03_GIS/ground_trouth/sentinel_ismn_data/*',\n",
    "    features = ['VV','VH', 'ASCENDING','DESCENDING','Sentinel_A','Sentinel_B','NDVI','angle','ismn_id', 'soil_moisture'],\n",
    "    y_label = 'soil_moisture'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T12:45:01.526774Z",
     "start_time": "2022-02-02T12:44:11.874079Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp_lr_sm(\n",
    "    paths = 'C://Users/USER/Desktop/Master_Irrigation/03_GIS/ground_trouth/sentinel_ismn_data/*',\n",
    "    features = ['VV','VH', 'ASCENDING','DESCENDING','Sentinel_A','Sentinel_B','NDVI','angle','ismn_id','WaterVapor', 'soil_moisture'],\n",
    "    y_label = 'soil_moisture'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T12:46:03.495531Z",
     "start_time": "2022-02-02T12:45:01.542734Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp_lr_sm(\n",
    "    paths = 'C://Users/USER/Desktop/Master_Irrigation/03_GIS/ground_trouth/sentinel_ismn_data/*',\n",
    "    features = ['VV','VH', 'ASCENDING','DESCENDING','Sentinel_A','Sentinel_B','NDVI','angle','ismn_id','WaterVapor','NIR', 'soil_moisture'],\n",
    "    y_label = 'soil_moisture'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T12:50:39.545031Z",
     "start_time": "2022-02-02T12:48:44.193503Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp_lr_sm(\n",
    "    paths = 'C://Users/USER/Desktop/Master_Irrigation/03_GIS/ground_trouth/sentinel_ismn_data/*',\n",
    "    features = ['VV','VH', 'ASCENDING','DESCENDING','Sentinel_A','Sentinel_B','NDVI','angle','ismn_id','Aerosols', 'Blue',\n",
    "       'Green', 'Red', 'RedEdge1', 'RedEdge2', 'RedEdge3', 'RedEdge4','WaterVapor','NIR', 'soil_moisture'],\n",
    "    y_label = 'soil_moisture'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T12:52:25.196704Z",
     "start_time": "2022-02-02T12:50:39.560653Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp_lr_sm(\n",
    "    paths = 'C://Users/USER/Desktop/Master_Irrigation/03_GIS/ground_trouth/sentinel_ismn_data/*',\n",
    "    features = ['VV','VH', 'ASCENDING','DESCENDING','Sentinel_A','Sentinel_B','NDVI','angle','Aerosols', 'Blue',\n",
    "       'Green', 'Red', 'RedEdge1', 'RedEdge2', 'RedEdge3', 'RedEdge4','WaterVapor','NIR', 'soil_moisture'],\n",
    "    y_label = 'soil_moisture'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:irrigation_detection]",
   "language": "python",
   "name": "conda-env-irrigation_detection-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
