{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T16:41:13.291118Z",
     "start_time": "2022-02-05T16:25:22.420507Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!conda install -c conda --yes --prefix {sys.prefix} tensorflow, tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T16:42:49.462858Z",
     "start_time": "2022-02-05T16:42:45.753366Z"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T19:27:09.394415Z",
     "start_time": "2022-02-02T19:27:04.572739Z"
    }
   },
   "outputs": [],
   "source": [
    "# Files with data\n",
    "paths = glob('C://Users/USER/Desktop/Master_Irrigation/03_GIS/ground_trouth/sentinel_ismn_data/*',)\n",
    "paths.sort()\n",
    "\n",
    "# Create Station id linked with filepath\n",
    "ids = [x.split('\\\\')[-1].split('_')[0] for x in paths]\n",
    "files = dict(zip(ids,paths))\n",
    "\n",
    "# Load all files into one Dataframe\n",
    "gdf = gpd.tools.util.pd.concat(map(gpd.read_file, paths), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T19:31:27.435559Z",
     "start_time": "2022-02-02T19:31:27.363624Z"
    }
   },
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T11:18:36.703726Z",
     "start_time": "2022-02-02T11:18:36.130450Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set type of date column to datetime object\n",
    "gdf.date = gdf.date.astype('datetime64[ns]')\n",
    "\n",
    "# Convert int to timedelta in days\n",
    "s2_timedelta = [dt.timedelta(days=x) for x in gdf.s2_distance]\n",
    "gdf.s2_distance = s2_timedelta\n",
    "\n",
    "#Remove uneseccary columns\n",
    "gdf.drop(labels = ['CloudMask'], axis = 1, inplace = True)\n",
    "\n",
    "# Clean Nan Values within subset columns (major variables to inspect)\n",
    "gdf.dropna(how='any', subset=['soil_moisture', 'VV'], inplace=True)\n",
    "\n",
    "# Drop lower and upper 1% of data to eliminate outliers\n",
    "gdf = gdf[gdf.soil_moisture.gt(gdf.soil_moisture.quantile(0.01)) & gdf.soil_moisture.lt(gdf.soil_moisture.quantile(0.99))]\n",
    "gdf = gdf[gdf.VV.gt(gdf.VV.quantile(0.01)) & gdf.VV.lt(gdf.VV.quantile(0.99))]\n",
    "#gdf = gdf[gdf.NDVI.gt(gdf.NDVI.quantile(0.01)) & gdf.NDVI.lt(gdf.NDVI.quantile(0.99))]\n",
    "\n",
    "# Remove rows where ndvi is older than 30days\n",
    "gdf = gdf[gdf.s2_distance.gt(dt.timedelta(days=-7)) & gdf.s2_distance.lt(dt.timedelta(days=7))]\n",
    "\n",
    "# Select only sm and vv meassurements where soil is not in frozen state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:24:07.140433Z",
     "start_time": "2022-02-02T09:24:07.124844Z"
    }
   },
   "outputs": [],
   "source": [
    "len(gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale, Transform dataset according to regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:29:41.738144Z",
     "start_time": "2022-02-02T09:29:41.716011Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T11:19:33.323134Z",
     "start_time": "2022-02-02T11:19:33.311114Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop categorical data \n",
    "orbit = gdf.pop('orbit')\n",
    "platform = gdf.pop('platform')\n",
    "#soil_moisture_flag = gdf.pop('soil_moisture_flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T11:19:56.580032Z",
     "start_time": "2022-02-02T11:19:56.548782Z"
    }
   },
   "outputs": [],
   "source": [
    "gdf['ASCENDING'] = (orbit == 'ASCENDING')*1\n",
    "gdf['DESCENDING'] = (orbit == 'DESCENDING')*1\n",
    "\n",
    "gdf['Sentinel_A'] = (platform == 'A')*1\n",
    "gdf['Sentinel_B'] = (platform == 'B')*1\n",
    "\n",
    "#gdf['soil_moisture_flag'] = (orbit == 'A')*1\n",
    "#gdf['soil_moisture_flag'] = (orbit == 'B')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T12:43:26.593121Z",
     "start_time": "2022-02-02T12:43:26.555512Z"
    }
   },
   "outputs": [],
   "source": [
    "gdf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:59:47.904271Z",
     "start_time": "2022-02-02T09:59:47.888644Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(gdf[['VV', 'soil_moisture']]).reset_index(drop=True)\n",
    "train_df = df.sample(frac = 0.8, random_state=0)\n",
    "test_df = df.drop(train_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:29:12.773058Z",
     "start_time": "2022-02-02T09:29:11.835180Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(train_df, diag_kind = 'kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:59:51.512514Z",
     "start_time": "2022-02-02T09:59:51.474741Z"
    }
   },
   "outputs": [],
   "source": [
    "train_stats = train_df.describe()\n",
    "train_stats.pop('soil_moisture')\n",
    "train_stats = train_stats.transpose()\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split features from labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:59:59.061311Z",
     "start_time": "2022-02-02T09:59:59.045716Z"
    }
   },
   "outputs": [],
   "source": [
    "train_labels = train_df.pop('soil_moisture')\n",
    "test_labels = test_df.pop('soil_moisture')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:29:45.161656Z",
     "start_time": "2022-02-02T09:29:45.146259Z"
    }
   },
   "outputs": [],
   "source": [
    "csc = MinMaxScaler()\n",
    "lsc = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T10:01:02.067507Z",
     "start_time": "2022-02-02T10:01:02.063511Z"
    }
   },
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return (x - train_stats['mean']) / train_stats['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T10:01:28.662970Z",
     "start_time": "2022-02-02T10:01:28.646987Z"
    }
   },
   "outputs": [],
   "source": [
    "n_train_df = norm(train_df)\n",
    "n_test_df = norm(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:37:08.920570Z",
     "start_time": "2022-02-02T09:37:08.912580Z"
    }
   },
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T10:11:03.989543Z",
     "start_time": "2022-02-02T10:11:03.973922Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.nn import relu\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T08:53:52.078233Z",
     "start_time": "2022-02-02T08:53:52.062254Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T10:01:35.590423Z",
     "start_time": "2022-02-02T10:01:35.582462Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential([\n",
    "        layers.Dense(64, activation=relu, input_shape=[len(n_train_df.keys())]), # densly (fully connected) hidden layer\n",
    "        layers.Dense(64, activation=relu), # denly hidden layer\n",
    "        layers.Dense(1) #output layer\n",
    "    ])\n",
    "    \n",
    "    optimizer = RMSprop(0.001)\n",
    "    \n",
    "    model.compile(\n",
    "        loss = 'mse', # mean sqared error\n",
    "        optimizer = optimizer,\n",
    "        metrics = ['mae', 'mse']) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T10:01:37.388344Z",
     "start_time": "2022-02-02T10:01:37.352343Z"
    }
   },
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T10:05:26.569625Z",
     "start_time": "2022-02-02T10:05:26.554234Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T10:36:56.944933Z",
     "start_time": "2022-02-02T10:36:56.936943Z"
    }
   },
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "class Calls(Callback):\n",
    "    #Print dot every epoch while training\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 100 == 0: print('')\n",
    "        print('.', end='')\n",
    "    \n",
    "# stop the training when there is no improvement in the loss for three consecutive epochs.\n",
    "stop_improving = EarlyStopping(monitor='val_loss', patience=10)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T10:37:09.096891Z",
     "start_time": "2022-02-02T10:36:59.793026Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "\n",
    "history = model.fit(\n",
    "    x = n_train_df,\n",
    "    y = train_labels,\n",
    "    epochs = EPOCHS,\n",
    "    validation_split = 0.2, \n",
    "    verbose = 0,\n",
    "    callbacks = [Calls(), stop_improving])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T10:37:12.344532Z",
     "start_time": "2022-02-02T10:37:12.320592Z"
    }
   },
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T10:37:15.719165Z",
     "start_time": "2022-02-02T10:37:15.441520Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(hitsory):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error [MPG]')\n",
    "    plt.plot(hist['epoch'], hist['mae'],\n",
    "            label = 'Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mae'],\n",
    "            label = 'Val Error')\n",
    "    plt.legend()\n",
    "    plt.ylim([0,hist['mae'].max() + hist['mae'].max() * 0.5])\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Error [$MPG^2$]')\n",
    "    plt.plot(hist['epoch'], hist['mse'],\n",
    "            label = 'Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mse'],\n",
    "            label = 'Val Error')\n",
    "    plt.legend()\n",
    "    plt.ylim([0,hist['mse'].max() + hist['mse'].max() * 0.5])\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T10:39:19.826330Z",
     "start_time": "2022-02-02T10:39:19.676316Z"
    }
   },
   "outputs": [],
   "source": [
    "loss, mae, mse = model.evaluate(n_test_df, test_labels, verbose = 0)\n",
    "print(\"Testing set Mean Abs Error: {:5.2f} m^3/m^3\".format(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T10:43:54.288709Z",
     "start_time": "2022-02-02T10:43:54.038389Z"
    }
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict(n_test_ds).flatten()\n",
    "\n",
    "plt.scatter(test_labels, test_predictions)\n",
    "plt.xlabel('True Values m^3/m^3')\n",
    "plt.ylabel('Predictions m^3/m^3')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.xlim([0,plt.xlim()[1]])\n",
    "plt.ylim([0,plt.ylim()[1]])\n",
    "_ = plt.plot([-100,100], [-100,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T10:46:21.338346Z",
     "start_time": "2022-02-02T10:46:21.185620Z"
    }
   },
   "outputs": [],
   "source": [
    "error = test_predictions - test_labels\n",
    "plt.hist(error, bins=25)\n",
    "plt.xlabel('Prediction Error m^3/m^3')\n",
    "_ = plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Try: 2 Feature [sm, vv] / No Seperation between different Paramters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T08:47:26.819082Z",
     "start_time": "2022-02-02T08:47:26.799000Z"
    }
   },
   "outputs": [],
   "source": [
    "X = gdf['VV'].reset_index(drop=True).iloc[0:100]\n",
    "Y = gdf['soil_moisture'].reset_index(drop=True).iloc[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T08:49:32.073109Z",
     "start_time": "2022-02-02T08:49:15.007908Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "estimator = KerasRegressor(\n",
    "    build_fn = baseline_model,\n",
    "    epochs = 100, \n",
    "    batch_size = 5,\n",
    "    verbose = 0)\n",
    "kfold = KFold(n_splits = 10) #10-fold cross validation to evaluate the model\n",
    "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Baseline: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "print(f\"Baseline: {results.mean()}%.2f ({results.std()}%.2f) MSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:44:24.665132Z",
     "start_time": "2022-02-01T12:44:24.644994Z"
    }
   },
   "outputs": [],
   "source": [
    "features = ['VV', 'soil_moisture']\n",
    "df = gdf[features].reset_index(drop=True)\n",
    "sc_data = csc.fit_transform(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(sc_data[:,0],sc_data[:,1], test_size=0.25, random_state = 42, shuffle=False, stratify=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T12:47:58.610286Z",
     "start_time": "2022-02-01T12:47:58.580300Z"
    }
   },
   "outputs": [],
   "source": [
    "model = models.create_mlp(X_train, regress=True)\n",
    "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
    "model.compile(loss='mean_absolute_percentage_error', optimizer=opt)\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    x = X_train,\n",
    "    y = y_train,\n",
    "    validation_data = (X_test, y_test),\n",
    "    epoches = 200,\n",
    "    batch_size = 8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T11:35:54.228346Z",
     "start_time": "2022-02-01T11:35:54.212368Z"
    }
   },
   "outputs": [],
   "source": [
    "def prep_scaling(df, modus, features):\n",
    "    \"\"\"\n",
    "    Arguments: modus ['MinMax', 'LabelBinarizer']\n",
    "    \"\"\"\n",
    "    # Import modlues\n",
    "    from sklearn.preprocessing import LabelBinarizer\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    \n",
    "    # Initialize Scaler ?What is with negative numbers?\n",
    "    if modus == 'MinMax':\n",
    "        cs = MinMaxScaler()\n",
    "    elif modus == 'LabelBinarizer':\n",
    "        cs = LabelBinarizer()\n",
    "    \n",
    "    return cs.fit_transform(df[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = prep_scaling(\n",
    "    df = gdf,\n",
    "    modus = 'MinMax',\n",
    "    columns = ['VV', 'soil_moisture'],\n",
    "    )\n",
    "data_1 sklearn.model_selection.train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T11:31:01.723073Z",
     "start_time": "2022-02-01T11:31:01.707126Z"
    }
   },
   "outputs": [],
   "source": [
    "df_1 = gdf[['soil_moisture', 'VV']].reset_index(drop=True) #2 Feature Selection\n",
    "\n",
    "\n",
    "x = gdf.VV.reset_index(drop=True) # Sentinel 1 GRD VV Backscatter Coefficient\n",
    "y = gdf.soil_moisture.reset_index(drop=True) # Soil Moisture\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T10:44:57.822928Z",
     "start_time": "2022-01-15T10:44:57.355931Z"
    }
   },
   "outputs": [],
   "source": [
    "data = gpd.read_file(ismn_path + '\\ismn_ts_vv_sm_01.json')\n",
    "data['date'] = pd.to_datetime(data.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T10:00:17.852554Z",
     "start_time": "2022-01-13T10:00:17.552347Z"
    }
   },
   "outputs": [],
   "source": [
    "ms1_x, ms1_y, ms2_x, ms2_y, as1_x, as1_y, as2_x, as2_y = list(), list(),list(),list(),list(),list(),list(),list()\n",
    "\n",
    "for station in data.station.unique():\n",
    "    for year in data.date.dt.year.unique():\n",
    "        time_series = data[(data['station'] == station ) & (data['date'].dt.year == year) & (data['date'].dt.month.isin([3,4,5,6,7,8,9]))]\n",
    "        #Sentinel A Ascending \n",
    "        ms1_x.append(time_series[(time_series['sentinel'] == 'A') & (time_series['orbit_direction'] == 'ASCENDING')]['VV'])\n",
    "        ms1_y.append(time_series[(time_series['sentinel'] == 'A') & (time_series['orbit_direction'] == 'ASCENDING')][['angle', 'soil_moisture']])\n",
    "        # Sentinel B Ascending\n",
    "        ms2_x.append(time_series[(time_series['sentinel'] == 'B') & (time_series['orbit_direction'] == 'ASCENDING')]['VV'])\n",
    "        ms2_y.append(time_series[(time_series['sentinel'] == 'B') & (time_series['orbit_direction'] == 'ASCENDING')][['angle', 'soil_moisture']])\n",
    "        # Sentinel A Descending\n",
    "        as1_x.append(time_series[(time_series['sentinel'] == 'A') & (time_series['orbit_direction'] == 'DESCENDING')]['VV'])\n",
    "        as1_y.append(time_series[(time_series['sentinel'] == 'A') & (time_series['orbit_direction'] == 'DESCENDING')][['angle', 'soil_moisture']])\n",
    "        # Sentinel B Descending\n",
    "        as2_x.append(time_series[(time_series['sentinel'] == 'B') & (time_series['orbit_direction'] == 'DESCENDING')]['VV'])\n",
    "        as2_y.append(time_series[(time_series['sentinel'] == 'B') & (time_series['orbit_direction'] == 'DESCENDING')][['angle', 'soil_moisture']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Sentinel-1 Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T09:54:47.484024Z",
     "start_time": "2022-01-12T09:54:47.467990Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_s1_metadata(filename):\n",
    "    from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "    # connect to the API\n",
    "    api = SentinelAPI('till90', '201184Till', 'https://scihub.copernicus.eu/dhus')\n",
    "    # Query Metadata by filename\n",
    "    products = api.query(filename = f'{filename}*')\n",
    "    return api.to_dataframe(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T10:02:35.970903Z",
     "start_time": "2022-01-12T10:02:35.786067Z"
    }
   },
   "outputs": [],
   "source": [
    "get_s1_metadata('S1A_IW_GRDH_1SDV_20150104T051921_20150104T051946_004017_004D70_3611').orbitdirection.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data to train the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ismn in-situ soil moisture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T10:44:53.994699Z",
     "start_time": "2022-01-15T10:44:53.990706Z"
    }
   },
   "outputs": [],
   "source": [
    "#path to single json files per station\n",
    "ismn_path = r'C:\\Users\\USER\\Desktop\\Master_Irrigation\\03_GIS\\ground_trouth\\ismn_archieve\\time_series'\n",
    "files = glob(ismn_path + '\\*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T11:28:47.022480Z",
     "start_time": "2022-01-12T11:28:47.007089Z"
    }
   },
   "outputs": [],
   "source": [
    "files = files[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T11:28:54.073849Z",
     "start_time": "2022-01-12T11:28:53.735124Z"
    }
   },
   "outputs": [],
   "source": [
    "#load time series in pandas\n",
    "ts_ismn_sm = [pd.read_json(x) for x in files]\n",
    "# Get coords from filename\n",
    "coords = [x.split('\\\\')[-1].split('_')[1:3] for x in files]\n",
    "# Create GeoDataFrame for every time series with geometry from filename \n",
    "ts_ismn_sm_gdf = [gpd.GeoDataFrame(data = ts_ismn_sm[x], geometry=gpd.points_from_xy(x = np.repeat(coords[x][1], len(ts_ismn_sm[x])), y = np.repeat(coords[x][0], len(ts_ismn_sm[x])))) for x in range(0,len(files))]\n",
    "# Concat all gdf to one geodataframe\n",
    "ts_ismn = gpd.tools.util.pd.concat(ts_ismn_sm_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T19:42:33.003083Z",
     "start_time": "2022-01-11T19:42:32.987679Z"
    }
   },
   "outputs": [],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T15:04:16.014727Z",
     "start_time": "2021-12-30T15:04:15.999136Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract regular sampled; 1 values for 1 day at the same time s1 meassure backscatter coeffienct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gee sentinel 1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T09:55:29.510850Z",
     "start_time": "2022-01-12T09:55:28.498744Z"
    }
   },
   "outputs": [],
   "source": [
    "#path to single json files per station\n",
    "gee_fc_path = r'C:\\Users\\USER\\Desktop\\Master_Irrigation\\03_GIS\\ground_trouth\\ismn_fc_gee_VV_na_clear.geojson'\n",
    "ts_ismn_bc = gpd.read_file(gee_fc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T10:57:55.789999Z",
     "start_time": "2022-01-12T10:05:37.845825Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract metadata from filename\n",
    "ts_ismn_bc['station'] = [x[-1] for x in ts_ismn_bc.id]\n",
    "ts_ismn_bc['sentinel'] = [x[2] for x in ts_ismn_bc.id]\n",
    "ts_ismn_bc['date'] = [datetime.strptime(x.split('_')[4][:15], '%Y%m%dT%H%M%S') for x in ts_ismn_bc.id]\n",
    "ts_ismn_bc['mode'] = [x[4:6] for x in ts_ismn_bc.id]\n",
    "ts_ismn_bc['type'] = [str(x[7:11]) for x in ts_ismn_bc.id]\n",
    "# only High Resolution types\n",
    "ts_ismn_bc = ts_ismn_bc[ts_ismn_bc['type'] == 'GRDH']\n",
    "#drop duplicates fix because when downloading vv data some sensors are at same postion but different depths\n",
    "ts_ismn_bc.drop_duplicates(['geometry', 'VV'], inplace=True)\n",
    "# Add Orbit Direction with sentinelsat query\n",
    "orbit_directions = list()\n",
    "for row in ts_ismn_bc.itertuples():\n",
    "    metadata = get_s1_metadata(row.id[:-2])\n",
    "    try:\n",
    "        orbit_directions.append(metadata.orbitdirection.values[0])\n",
    "    except:\n",
    "        orbit_directions.append(np.nan)\n",
    "ts_ismn_bc['orbit_direction'] = orbit_directions\n",
    "ts_ismn_bc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge data vv + sm ground trouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T11:37:26.717639Z",
     "start_time": "2022-01-12T11:29:06.146039Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add sm from ismn data to s1 vv data\n",
    "values = list()\n",
    "for row in ts_ismn_bc.itertuples():\n",
    "    time = row.date.round('1h')\n",
    "    geometry = row.geometry\n",
    "    # select all rows with same geometry (change x and y lat/lon maybe because of shaply module)\n",
    "    sm = ts_ismn.cx[geometry.y:geometry.y , geometry.x:geometry.x]\n",
    "    # select all rows with same time\n",
    "    sm = sm[sm.index == time]\n",
    "    # mean when multiple values nan when no values\n",
    "    if len(sm) == 0:\n",
    "        values.append(np.nan)\n",
    "    else:\n",
    "        values.append(np.mean(list(sm.soil_moisture)))\n",
    "        \n",
    "ts_ismn_bc['soil_moisture'] = values\n",
    "ts_ismn_bc.to_file(ismn_path + '\\ismn_ts_vv_sm_01.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T19:42:10.593980Z",
     "start_time": "2022-01-11T19:42:10.562704Z"
    }
   },
   "outputs": [],
   "source": [
    "ts_ismn_bc.station.unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:irrigation_detection]",
   "language": "python",
   "name": "conda-env-irrigation_detection-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
